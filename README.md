![alt text](Imagenes/Datawave_logo_suavizado.jpg)
# Proyecto grupal
## YELP & GOOGLE MAPS - REVIEWS AND RECOMMENDATIONS

## √çndice
- [Descripci√≥n del Proyecto](#descripci√≥n-del-proyecto--localizaci√≥n-√≥ptima-y-an√°lisis-de-√©xito-gastron√≥mico)
- [Presentaci√≥n del equipo](#presentaci√≥n-del-equipo)
- [Objetivos del proyecto](#objetivos-del-proyecto)
- [Alcance](#alcance)
- [Motivos para la elecci√≥n del alcance del proyecto](#motivos-para-la-elecci√≥n-del-alcance-del-proyecto)
- [Pipeline END to END](#pipeline-end-to-end)
- [Tecnolog√≠as y herramientas utilizadas](#tecnolog√≠as-y-herramientas-utilizadas)
- [Key Performance Indicators (KPI)](#key-performance-indicators-(kpi))
- [Metodolog√≠a de Trabajo: SCRUM](#metodolog√≠a-de-trabajo:-scrum)
- üìä[VER DASHBOARD](https://lookerstudio.google.com/reporting/2976b04b-0a80-499d-be27-8ea8a8820c20)
  
## Descripci√≥n del Proyecto ‚Äì *Localizaci√≥n √ìptima y An√°lisis de √âxito Gastron√≥mico*

**Empresa: DataWave. Data Solutions**

### Problem√°tica

Un cliente con capital disponible desea iniciar un emprendimiento gastron√≥mico en los Estados Unidos. Su objetivo es maximizar las posibilidades de √©xito desde el inicio, seleccionando:

1. **El estado m√°s favorable demogr√°ficamente**, considerando la **mayor densidad poblacional**.
2. **La categor√≠a de restaurante con mayores probabilidades de √©xito**, determinada a partir de **rese√±as reales de clientes**.

### Soluci√≥n Propuesta

Desde **DataWave Data Solutions**, desarrollamos una soluci√≥n integral basada en ciencia de datos, que combina datos demogr√°ficos oficiales con an√°lisis inteligente de rese√±as en l√≠nea.

#### 1. An√°lisis Demogr√°fico
Usamos datos del **U.S. Census Bureau** para identificar el **estado con mayor densidad poblacional**. Esta m√©trica permite enfocar el an√°lisis en zonas con alta concentraci√≥n de personas, lo que incrementa la visibilidad y potencial de captaci√≥n de clientes.

#### 2. An√°lisis de Rese√±as y Tendencias Gastron√≥micas
Utilizando datasets de **Google Maps** y **Yelp**, realizamos:
- Clasificaci√≥n por categor√≠a gastron√≥mica
- An√°lisis de sentimientos sobre rese√±as
- Identificaci√≥n de categor√≠as con mayor proporci√≥n de rese√±as positivas

### Beneficios para el Cliente

- ‚úÖ **Ubicaci√≥n estrat√©gica:** seleccionada con base en datos reales de poblaci√≥n.
- ‚úÖ **Reducci√≥n de riesgo:** mediante decisiones fundamentadas en datos de comportamiento y opini√≥n del consumidor.
- ‚úÖ **Recomendaci√≥n personalizada:** del tipo de restaurante m√°s prometedor, alineado con preferencias del mercado.

## Presentaci√≥n del equipo

![alt text](Imagenes/Datawave_grupo.jpg)

## Objetivos del proyecto

- Predecir los rubros con mayor crecimiento o declive
- Identificar mejores ubicaciones seg√∫n densidad y demanda
- Implementar un sistema de recomendaci√≥n personalizado
- Generar dashboards claros y accionables
- Desarrollar un sistema que actualice rese√±as autom√°ticamente

## Alcance

El presente proyecto contempla, en su fase inicial, la recolecci√≥n, limpieza y an√°lisis de datos demogr√°ficos y comerciales con el objetivo de identificar el estado de mayor potencial para la apertura de un primer local gastron√≥mico. Esta selecci√≥n se basar√° en indicadores como la densidad poblacional, caracter√≠sticas socioecon√≥micas y preferencias de consumo. De forma complementaria, se analizar√°n rese√±as y puntuaciones de restaurantes a nivel nacional para determinar la categor√≠a gastron√≥mica con mayores probabilidades de √©xito, utilizando t√©cnicas de an√°lisis de sentimientos y miner√≠a de texto.

Esta primera implementaci√≥n funcionar√° como prueba piloto, permitiendo validar hip√≥tesis comerciales y operativas en un entorno real.

En una segunda etapa, ya contemplada en la planificaci√≥n futura del proyecto, se prev√© el desarrollo e implementaci√≥n de un sistema de recomendaci√≥n basado en aprendizaje autom√°tico. Este modelo permitir√° escalar la estrategia de expansi√≥n, identificando nuevas ubicaciones √≥ptimas para la instalaci√≥n de sucursales en otros estados del pa√≠s, en funci√≥n de patrones demogr√°ficos, comportamientos de consumo y desempe√±o del local inicial.

## Motivos para la elecci√≥n del alcance del proyecto

1. **Reducci√≥n de riesgos en la inversi√≥n inicial:** Iniciar con una √∫nica ubicaci√≥n permite evaluar la viabilidad del emprendimiento con una inversi√≥n controlada, reduciendo el riesgo financiero antes de escalar el modelo a otros estados.
2. **Validaci√≥n del modelo de an√°lisis:** Esta primera fase permite comprobar la efectividad del enfoque anal√≠tico propuesto (demograf√≠a + an√°lisis de rese√±as), asegurando que las herramientas y m√©todos empleados son adecuados antes de su aplicaci√≥n a gran escala.
3. **Facilidad de implementaci√≥n:** Concentrarse en un √∫nico local piloto permite una mayor supervisi√≥n y control de los procesos operativos, log√≠sticos y comerciales, facilitando ajustes en tiempo real seg√∫n el comportamiento del mercado.
4. **Obtenci√≥n de datos reales para feedback:** El funcionamiento del local inicial generar√° datos propios (ventas, satisfacci√≥n de clientes, preferencias locales) que servir√°n para entrenar y ajustar el futuro modelo de recomendaci√≥n.
5. **Estrategia de expansi√≥n progresiva:** Este enfoque gradual facilita el dise√±o de una hoja de ruta basada en evidencias, permitiendo escalar el negocio de manera sostenible y con fundamentos s√≥lidos.
6. **Optimizaci√≥n de recursos t√©cnicos:** Al limitar el an√°lisis inicial a un estado y un rubro espec√≠fico, se permite una investigaci√≥n m√°s profunda y detallada, maximizando la calidad de los insights sin dispersar los recursos del equipo.
7. **Mayor claridad para la toma de decisiones:** Un alcance acotado ayuda a mantener el foco en objetivos concretos, facilitando la toma de decisiones informadas y medibles en el corto plazo.

## Pipeline END to END

### Resumen del flujo de datos optimizado

```
[Extracci√≥n API / JSON]
        ‚Üì
[Ingesta a GCS (raw layer)]
        ‚Üì
[Cloud Composer (Airflow) ejecuta limpieza]
        ‚Üì
[Cloud Functions o Dataproc realiza transformaci√≥n]
        ‚Üì
[BigQuery (staging ‚Üí model layer)]
        ‚Üì
[Jupyter Notebook / Colab para EDA, NLP y ML]
        ‚Üì
[Modelo deploy: Cloud Run o Vertex AI Endpoint]
        ‚Üì
[Dashboard: Looker Studio]
```

### Etapas y servicios recomendados

#### 1. Ingesta de datos ‚Üí Google Cloud Storage (GCS)
- Objetivo: almacenar datos crudos
- Herramientas: Cloud Functions, Airflow, GCS buckets

#### 2. Limpieza b√°sica ‚Üí Cloud Composer (Airflow)
- Orquestaci√≥n con DAGs personalizados

#### 3. Transformaci√≥n avanzada ‚Üí Cloud Functions o Cloud Dataproc
- Scripts ligeros (Functions) o flujos pesados (Dataproc/Apache Beam)

#### 4. Almacenamiento ‚Üí BigQuery
- Modelo estrella o snowflake: `fact_reviews`, `dim_business`, etc.

#### 5. EDA y NLP ‚Üí Google Colab o Vertex AI Workbench
- Librer√≠as: pandas-gbq, nltk, vader, etc.

#### 6. Machine Learning ‚Üí Vertex AI
- Entrenamiento, validaci√≥n y deploy de modelos

#### 7. Deploy del producto ‚Üí Cloud Run o Vertex AI Endpoint
- Streamlit App o API REST (FastAPI)

#### 8. Dashboard final ‚Üí Looker Studio

### Automatizaci√≥n con Airflow (Composer)

1. Ingestar archivo JSON
2. Limpiar con Cloud Function
3. Cargar en BigQuery
4. Transformar a capa modelada
5. Ejecutar modelo y actualizar salida

![alt text](<Imagenes/pipline bonito.svg>)

## Tecnolog√≠as y herramientas utilizadas

| Tecnolog√≠a / Servicio     | Categor√≠a              | Funci√≥n en el pipeline                                                                 |
|---------------------------|------------------------|----------------------------------------------------------------------------------------|
| Google Cloud Storage      | Almacenamiento         | Repositorio de datos crudos y preprocesados                                           |
| Cloud Composer            | Orquestaci√≥n           | Orquestador de procesos ETL con Apache Airflow                                        |
| Cloud Functions           | Procesamiento ligero   | Funciones para limpieza y transformaci√≥n sin servidor                                 |
| Cloud Dataporc            | Procesamiento escalable| Para cargas grandes o procesamiento en streaming                                      |
| BigQuery                  | Data Warehouse         | Consulta r√°pida sobre grandes vol√∫menes, con modelo estructurado                     |
| BERT / Cosine similarity  | Machine Learning       | Entrenamiento, validaci√≥n y despliegue de modelos                                     |
| Looker Studio             | Visualizaci√≥n          | Dashboards interactivos conectados directamente a BigQuery                           |



## Key Performance Indicators (KPI)

A continuaci√≥n se describen los KPIs clave definidos para evaluar tendencias, oportunidades de mercado y efectividad del modelo en el proyecto.

---

## KPI 1 ‚Äî CSAT (Customer Satisfaction Score)

**Descripci√≥n:**
El CSAT mide el nivel de satisfacci√≥n del cliente tras una interacci√≥n (compra, visita, rese√±a, etc.) mediante encuestas con una escala de 1 (muy insatisfecho) a 5 (muy satisfecho).

**F√≥rmula:**
CSAT (%) = (Respuestas positivas / Total de respuestas) * 100
Se consideran positivas las respuestas de 4 o 5 estrellas.

**Objetivo:**
Evaluar la satisfacci√≥n percibida y detectar oportunidades de mejora en la experiencia del cliente.

**Meta:**
Mantener el CSAT en crecimiento constante a√±o a a√±o.

**Ejemplo:**
90 respuestas positivas de 150 totales ‚Üí CSAT = 60%

---

## KPI 2 ‚Äî Crecimiento >10% en Review Counts (Primer A√±o)

**Descripci√≥n:**
Mide el incremento en la cantidad de rese√±as publicadas (Yelp y Google) durante el primer a√±o del proyecto, comparado con el volumen inicial (baseline).

**F√≥rmula:**
Crecimiento (%) = ((Reviews a√±o_actual - Reviews a√±o_anterior) / Reviews a√±o_anterior) * 100

**Objetivo:**
Evaluar el crecimiento de la actividad y el engagement de los usuarios, as√≠ como la visibilidad generada por el proyecto.

**Meta:**
Superar un crecimiento del 10% en el n√∫mero de rese√±as al cabo del primer a√±o.

**Ejemplo:**
50.000 rese√±as iniciales ‚Üí 56.000 al final del primer a√±o ‚Üí Crecimiento = 12%

---

## KPI 3 ‚Äî NPS (Net Promoter Score)

**Descripci√≥n:**
El NPS mide la lealtad del cliente y su disposici√≥n a recomendar el negocio, basado en encuestas con una escala de 0 (nada probable) a 10 (muy probable).

**F√≥rmula:**
Los encuestados se clasifican como:

**Promotores: 9‚Äì10**

Pasivos: 7‚Äì8 (no se consideran en el c√°lculo)

Detractores: 0‚Äì6

NPS = % Promotores - % Detractores
Rango posible: de -100 a +100.

**Objetivo:**
Evaluar la lealtad y satisfacci√≥n profunda del cliente, as√≠ como la probabilidad de recomendaciones boca a boca.

**Meta:**
Incrementar el NPS a√±o tras a√±o como indicador de fidelizaci√≥n y reputaci√≥n.

**Ejemplo:**
200 encuestados ‚Üí 60% Promotores, 20% Detractores ‚Üí NPS = 40

---

## Metodolog√≠a de Trabajo: SCRUM

Para el desarrollo del proyecto se adopt√≥ la metodolog√≠a √°gil **SCRUM**, orientada a maximizar la colaboraci√≥n en equipo, la adaptabilidad al cambio y la entrega incremental de valor.

### ¬øQu√© es SCRUM?

SCRUM es un marco de trabajo √°gil que permite gestionar proyectos complejos de forma eficiente mediante iteraciones cortas llamadas **sprints**, promoviendo la mejora continua y la r√°pida entrega de productos funcionales.

### Estructura del equipo SCRUM

- **Product Owner (PO):** Representa los intereses del cliente. Define prioridades, valida entregables y ajusta el backlog seg√∫n las necesidades del negocio.
- **Scrum Master:** Facilita el proceso SCRUM, remueve obst√°culos y asegura el cumplimiento de la metodolog√≠a.
- **Equipo de desarrollo:** En este caso, compuesto por:
  - 2 Data Engineers
  - 2 Data Analysts
  - 1 ML Engineer

### Artefactos SCRUM

- **Product Backlog:** Lista priorizada de tareas y funcionalidades necesarias para cumplir los objetivos del proyecto.
- **Sprint Backlog:** Subconjunto del Product Backlog seleccionado para trabajarse durante un sprint.
- **Incremento:** Resultado funcional del sprint que puede presentarse al PO.

### Ceremonias SCRUM utilizadas

| Ceremonia         | Frecuencia      | Descripci√≥n |
|-------------------|-----------------|-------------|
| Sprint Planning   | Al inicio de cada sprint | El equipo define qu√© tareas se van a realizar y c√≥mo. |
| Daily Scrum       | Diariamente     | Reuni√≥n de 15 minutos para revisar avances, obst√°culos y plan diario. |
| Sprint Review     | Fin del sprint  | Se muestra el trabajo completado al Product Owner. Se recibe feedback. |
| Sprint Retrospective | Fin del sprint | Reflexi√≥n sobre el proceso, identificando mejoras para el pr√≥ximo sprint. |

### Estructura de trabajo en el proyecto

- Duraci√≥n del proyecto: **6 semanas**
- Dividido en **3 sprints** de 2 semanas cada uno
- Entregables definidos por sprint, validados con el PO
- Gesti√≥n de tareas y seguimiento mediante tableros (Kanban en GitHub Projects o Trello)

### Beneficios obtenidos

- Claridad de roles y prioridades
- Mejora continua en cada sprint
- Capacidad de adaptaci√≥n ante cambios de requerimientos
- Trabajo colaborativo y transparente
