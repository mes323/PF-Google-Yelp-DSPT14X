{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d491034",
   "metadata": {},
   "source": [
    "### ETL Review 5 estados - GMaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21d1bb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import gc "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3918610c",
   "metadata": {},
   "source": [
    "#### Columbia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a4f50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta donde están los archivos JSON\n",
    "json_folder_path = r\"C:/Users/jano_/Documents/Proyecto Final Grupal/Google Maps/reviews-estados/review-District_of_Columbia\"\n",
    "\n",
    "# Lista de archivos JSON en la carpeta\n",
    "json_files = [f for f in os.listdir(json_folder_path) if f.endswith('.json')]\n",
    "\n",
    "# Ruta de destino para los archivos Parquet\n",
    "parquet_folder_path = r\"C:/Users/jano_/Documents/Proyecto Final Grupal/Google Maps/reviews-estados/review-District_of_Columbia\"\n",
    "\n",
    "# Iterar sobre cada archivo JSON\n",
    "for json_file in json_files:\n",
    "    # Construir la ruta completa del archivo JSON\n",
    "    json_file_path = os.path.join(json_folder_path, json_file)\n",
    "    \n",
    "    # Leer el archivo JSON con Pandas\n",
    "    df = pd.read_json(json_file_path, lines=True)\n",
    "    \n",
    "    # Crear la ruta de destino Parquet, usando el nombre del archivo JSON\n",
    "    parquet_file_path = os.path.join(parquet_folder_path, json_file.replace('.json', '.parquet'))\n",
    "    \n",
    "    df_parquet = df\n",
    "\n",
    "    # Guardar el DataFrame transformado en Parquet\n",
    "    df_parquet.to_parquet(parquet_file_path, engine='pyarrow', index=False)\n",
    "    \n",
    "    # Limpiar memoria eliminando el DataFrame\n",
    "    del df\n",
    "    gc.collect()  # Llamada al recolector de basura para liberar memoria\n",
    "\n",
    "    print(f\"Archivo {json_file} procesado y guardado como Parquet en {parquet_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae682e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo 1.parquet procesado y agregado\n",
      "Archivo 2.parquet procesado y agregado\n",
      "Archivo 3.parquet procesado y agregado\n",
      "Archivo 4.parquet procesado y agregado\n",
      "Todos los archivos fueron procesados\n"
     ]
    }
   ],
   "source": [
    "parquet_files = [f for f in os.listdir(parquet_folder_path) if f.endswith('.parquet')]\n",
    "\n",
    "df_district_of_columbia = pd.DataFrame()\n",
    "\n",
    "# Leer y procesar cada archivo Parquet de manera incremental\n",
    "for file in parquet_files:\n",
    "    file_path = os.path.join(parquet_folder_path, file)\n",
    "    \n",
    "    # Leer el archivo Parquet\n",
    "    df = pd.read_parquet(file_path)\n",
    "    \n",
    "    # Concatenar al DataFrame total\n",
    "    df_district_of_columbia = pd.concat([df_district_of_columbia, df], ignore_index=True)\n",
    "    \n",
    "    # Limpiar memoria eliminando el DataFrame temporal\n",
    "    del df\n",
    "    gc.collect()  # Forzar la recolección de basura\n",
    "\n",
    "    print(f\"Archivo {file} procesado y agregado\")\n",
    "\n",
    "print(\"Todos los archivos fueron procesados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9402993b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>time</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>pics</th>\n",
       "      <th>resp</th>\n",
       "      <th>gmap_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.042564e+20</td>\n",
       "      <td>Petre Ene</td>\n",
       "      <td>1551027526726</td>\n",
       "      <td>4</td>\n",
       "      <td>the food is really good, I had a great experie...</td>\n",
       "      <td>[{'url': ['https://lh5.googleusercontent.com/p...</td>\n",
       "      <td>None</td>\n",
       "      <td>0x89b7b7851b06ef6b:0x5f356b1eb1da27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.086426e+20</td>\n",
       "      <td>Keshava Mysore</td>\n",
       "      <td>1510920735052</td>\n",
       "      <td>4</td>\n",
       "      <td>High prices for not so big portions! But I thi...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x89b7b7851b06ef6b:0x5f356b1eb1da27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.118429e+20</td>\n",
       "      <td>Carol G</td>\n",
       "      <td>1543249586598</td>\n",
       "      <td>2</td>\n",
       "      <td>The gelato looked \"old\" and ended up having co...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x89b7b7851b06ef6b:0x5f356b1eb1da27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.102994e+20</td>\n",
       "      <td>翟泉</td>\n",
       "      <td>1496597796978</td>\n",
       "      <td>4</td>\n",
       "      <td>(Translated by Google) The fast food restauran...</td>\n",
       "      <td>[{'url': ['https://lh5.googleusercontent.com/p...</td>\n",
       "      <td>None</td>\n",
       "      <td>0x89b7b7851b06ef6b:0x5f356b1eb1da27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.164480e+20</td>\n",
       "      <td>Kitae Yim</td>\n",
       "      <td>1540701399450</td>\n",
       "      <td>1</td>\n",
       "      <td>(Translated by Google) The food is barely edib...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x89b7b7851b06ef6b:0x5f356b1eb1da27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564778</th>\n",
       "      <td>1.006178e+20</td>\n",
       "      <td>Eastwood Cameron</td>\n",
       "      <td>1562283008242</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x89b7b7c0896f06db:0xb1616aab085a8353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564779</th>\n",
       "      <td>1.183827e+20</td>\n",
       "      <td>V</td>\n",
       "      <td>1519337600592</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x89b7b7c0896f06db:0xb1616aab085a8353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564780</th>\n",
       "      <td>1.058797e+20</td>\n",
       "      <td>Francisco de Zavalía</td>\n",
       "      <td>1568771759420</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x89b7b7c0896f06db:0xb1616aab085a8353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564781</th>\n",
       "      <td>1.157440e+20</td>\n",
       "      <td>Charleen Lim</td>\n",
       "      <td>1522153548594</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x89b7b7c0896f06db:0xb1616aab085a8353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564782</th>\n",
       "      <td>1.038073e+20</td>\n",
       "      <td>Rodrigo Ferro</td>\n",
       "      <td>1559302218699</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x89b7b7c0896f06db:0xb1616aab085a8353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>564783 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id                  name           time  rating  \\\n",
       "0       1.042564e+20             Petre Ene  1551027526726       4   \n",
       "1       1.086426e+20        Keshava Mysore  1510920735052       4   \n",
       "2       1.118429e+20               Carol G  1543249586598       2   \n",
       "3       1.102994e+20                    翟泉  1496597796978       4   \n",
       "4       1.164480e+20             Kitae Yim  1540701399450       1   \n",
       "...              ...                   ...            ...     ...   \n",
       "564778  1.006178e+20      Eastwood Cameron  1562283008242       5   \n",
       "564779  1.183827e+20                     V  1519337600592       5   \n",
       "564780  1.058797e+20  Francisco de Zavalía  1568771759420       5   \n",
       "564781  1.157440e+20          Charleen Lim  1522153548594       5   \n",
       "564782  1.038073e+20         Rodrigo Ferro  1559302218699       5   \n",
       "\n",
       "                                                     text  \\\n",
       "0       the food is really good, I had a great experie...   \n",
       "1       High prices for not so big portions! But I thi...   \n",
       "2       The gelato looked \"old\" and ended up having co...   \n",
       "3       (Translated by Google) The fast food restauran...   \n",
       "4       (Translated by Google) The food is barely edib...   \n",
       "...                                                   ...   \n",
       "564778                                               None   \n",
       "564779                                               None   \n",
       "564780                                               None   \n",
       "564781                                               None   \n",
       "564782                                               None   \n",
       "\n",
       "                                                     pics  resp  \\\n",
       "0       [{'url': ['https://lh5.googleusercontent.com/p...  None   \n",
       "1                                                    None  None   \n",
       "2                                                    None  None   \n",
       "3       [{'url': ['https://lh5.googleusercontent.com/p...  None   \n",
       "4                                                    None  None   \n",
       "...                                                   ...   ...   \n",
       "564778                                               None  None   \n",
       "564779                                               None  None   \n",
       "564780                                               None  None   \n",
       "564781                                               None  None   \n",
       "564782                                               None  None   \n",
       "\n",
       "                                      gmap_id  \n",
       "0         0x89b7b7851b06ef6b:0x5f356b1eb1da27  \n",
       "1         0x89b7b7851b06ef6b:0x5f356b1eb1da27  \n",
       "2         0x89b7b7851b06ef6b:0x5f356b1eb1da27  \n",
       "3         0x89b7b7851b06ef6b:0x5f356b1eb1da27  \n",
       "4         0x89b7b7851b06ef6b:0x5f356b1eb1da27  \n",
       "...                                       ...  \n",
       "564778  0x89b7b7c0896f06db:0xb1616aab085a8353  \n",
       "564779  0x89b7b7c0896f06db:0xb1616aab085a8353  \n",
       "564780  0x89b7b7c0896f06db:0xb1616aab085a8353  \n",
       "564781  0x89b7b7c0896f06db:0xb1616aab085a8353  \n",
       "564782  0x89b7b7c0896f06db:0xb1616aab085a8353  \n",
       "\n",
       "[564783 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_district_of_columbia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ea20cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_district_of_columbia = df_district_of_columbia.drop(columns=[\"pics\", \"resp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db39847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>time</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>gmap_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.042564e+20</td>\n",
       "      <td>Petre Ene</td>\n",
       "      <td>1551027526726</td>\n",
       "      <td>4</td>\n",
       "      <td>the food is really good, I had a great experie...</td>\n",
       "      <td>0x89b7b7851b06ef6b:0x5f356b1eb1da27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.086426e+20</td>\n",
       "      <td>Keshava Mysore</td>\n",
       "      <td>1510920735052</td>\n",
       "      <td>4</td>\n",
       "      <td>High prices for not so big portions! But I thi...</td>\n",
       "      <td>0x89b7b7851b06ef6b:0x5f356b1eb1da27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.118429e+20</td>\n",
       "      <td>Carol G</td>\n",
       "      <td>1543249586598</td>\n",
       "      <td>2</td>\n",
       "      <td>The gelato looked \"old\" and ended up having co...</td>\n",
       "      <td>0x89b7b7851b06ef6b:0x5f356b1eb1da27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.102994e+20</td>\n",
       "      <td>翟泉</td>\n",
       "      <td>1496597796978</td>\n",
       "      <td>4</td>\n",
       "      <td>(Translated by Google) The fast food restauran...</td>\n",
       "      <td>0x89b7b7851b06ef6b:0x5f356b1eb1da27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.164480e+20</td>\n",
       "      <td>Kitae Yim</td>\n",
       "      <td>1540701399450</td>\n",
       "      <td>1</td>\n",
       "      <td>(Translated by Google) The food is barely edib...</td>\n",
       "      <td>0x89b7b7851b06ef6b:0x5f356b1eb1da27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564778</th>\n",
       "      <td>1.006178e+20</td>\n",
       "      <td>Eastwood Cameron</td>\n",
       "      <td>1562283008242</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>0x89b7b7c0896f06db:0xb1616aab085a8353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564779</th>\n",
       "      <td>1.183827e+20</td>\n",
       "      <td>V</td>\n",
       "      <td>1519337600592</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>0x89b7b7c0896f06db:0xb1616aab085a8353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564780</th>\n",
       "      <td>1.058797e+20</td>\n",
       "      <td>Francisco de Zavalía</td>\n",
       "      <td>1568771759420</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>0x89b7b7c0896f06db:0xb1616aab085a8353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564781</th>\n",
       "      <td>1.157440e+20</td>\n",
       "      <td>Charleen Lim</td>\n",
       "      <td>1522153548594</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>0x89b7b7c0896f06db:0xb1616aab085a8353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564782</th>\n",
       "      <td>1.038073e+20</td>\n",
       "      <td>Rodrigo Ferro</td>\n",
       "      <td>1559302218699</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>0x89b7b7c0896f06db:0xb1616aab085a8353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>564783 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id                  name           time  rating  \\\n",
       "0       1.042564e+20             Petre Ene  1551027526726       4   \n",
       "1       1.086426e+20        Keshava Mysore  1510920735052       4   \n",
       "2       1.118429e+20               Carol G  1543249586598       2   \n",
       "3       1.102994e+20                    翟泉  1496597796978       4   \n",
       "4       1.164480e+20             Kitae Yim  1540701399450       1   \n",
       "...              ...                   ...            ...     ...   \n",
       "564778  1.006178e+20      Eastwood Cameron  1562283008242       5   \n",
       "564779  1.183827e+20                     V  1519337600592       5   \n",
       "564780  1.058797e+20  Francisco de Zavalía  1568771759420       5   \n",
       "564781  1.157440e+20          Charleen Lim  1522153548594       5   \n",
       "564782  1.038073e+20         Rodrigo Ferro  1559302218699       5   \n",
       "\n",
       "                                                     text  \\\n",
       "0       the food is really good, I had a great experie...   \n",
       "1       High prices for not so big portions! But I thi...   \n",
       "2       The gelato looked \"old\" and ended up having co...   \n",
       "3       (Translated by Google) The fast food restauran...   \n",
       "4       (Translated by Google) The food is barely edib...   \n",
       "...                                                   ...   \n",
       "564778                                               None   \n",
       "564779                                               None   \n",
       "564780                                               None   \n",
       "564781                                               None   \n",
       "564782                                               None   \n",
       "\n",
       "                                      gmap_id  \n",
       "0         0x89b7b7851b06ef6b:0x5f356b1eb1da27  \n",
       "1         0x89b7b7851b06ef6b:0x5f356b1eb1da27  \n",
       "2         0x89b7b7851b06ef6b:0x5f356b1eb1da27  \n",
       "3         0x89b7b7851b06ef6b:0x5f356b1eb1da27  \n",
       "4         0x89b7b7851b06ef6b:0x5f356b1eb1da27  \n",
       "...                                       ...  \n",
       "564778  0x89b7b7c0896f06db:0xb1616aab085a8353  \n",
       "564779  0x89b7b7c0896f06db:0xb1616aab085a8353  \n",
       "564780  0x89b7b7c0896f06db:0xb1616aab085a8353  \n",
       "564781  0x89b7b7c0896f06db:0xb1616aab085a8353  \n",
       "564782  0x89b7b7c0896f06db:0xb1616aab085a8353  \n",
       "\n",
       "[564783 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_district_of_columbia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8374deec",
   "metadata": {},
   "source": [
    "#### New Jersey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f725c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta de origen\n",
    "json_folder_path = r\"C:/Users/jano_/Documents/Proyecto Final Grupal/Google Maps/reviews-estados/review-New_Jersey\"\n",
    "\n",
    "# Lista de archivos JSON en la carpeta.\n",
    "json_files = [f for f in os.listdir(json_folder_path) if f.endswith('.json')]\n",
    "\n",
    "# Ruta de destino\n",
    "parquet_folder_path = r\"C:/Users/jano_/Documents/Proyecto Final Grupal/Google Maps/reviews-estados/review-New_Jersey\"\n",
    "\n",
    "# Bucle para leer y convertir todos los archivos JSON a Parquet.\n",
    "for json_file in json_files:\n",
    "    # Construir la ruta completa del archivo JSON.\n",
    "    json_file_path = os.path.join(json_folder_path, json_file)\n",
    "    \n",
    "    df = pd.read_json(json_file_path, lines=True)\n",
    "    \n",
    "    # Crear la ruta de destino Parquet, usando el nombre del archivo JSON.\n",
    "    parquet_file_path = os.path.join(parquet_folder_path, json_file.replace('.json', '.parquet'))\n",
    "    \n",
    "    df_parquet = df\n",
    "\n",
    "    df_parquet.to_parquet(parquet_file_path, engine='pyarrow', index=False)\n",
    "    \n",
    "    # Eliminamos df en el bucle y liberamos memoria, para ir convirtiendo 1 por iteración.\n",
    "    del df\n",
    "    gc.collect()  \n",
    "\n",
    "    print(f\"Archivo {json_file} procesado y guardado como Parquet en {parquet_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7e851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_files = [f for f in os.listdir(parquet_folder_path) if f.endswith('.parquet')]\n",
    "\n",
    "df_new_jersey = pd.DataFrame()\n",
    "\n",
    "# Leemos y procesamos cada archivo Parquet de manera incremental\n",
    "for file in parquet_files:\n",
    "    file_path = os.path.join(parquet_folder_path, file)\n",
    "    \n",
    "    df = pd.read_parquet(file_path)\n",
    "    \n",
    "    # Concatenamos cada archivo para unir todos los datos\n",
    "    df_new_jersey = pd.concat([df_new_jersey, df], ignore_index=True)\n",
    "    \n",
    "    # Eliminamos df en el bucle y liberamos memoria, para ir procesando y concatenando de 1 por iteración.\n",
    "    del df\n",
    "    gc.collect()\n",
    "\n",
    "    print(f\"Archivo {file} procesado y agregado\")\n",
    "\n",
    "print(\"Todos los archivos fueron procesados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8b1375",
   "metadata": {},
   "source": [
    "#### Rhode Island"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6d9233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta de origen\n",
    "json_folder_path = r\"C:/Users/jano_/Documents/Proyecto Final Grupal/Google Maps/reviews-estados/review-Rhode_Island\"\n",
    "\n",
    "# Ruta de destino\n",
    "parquet_folder_path = r\"C:/Users/jano_/Documents/Proyecto Final Grupal/Google Maps/reviews-estados/review-Rhode_Island\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeca4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de archivos JSON en la carpeta.\n",
    "json_files = [f for f in os.listdir(json_folder_path) if f.endswith('.json')]\n",
    "\n",
    "# Bucle para leer y convertir todos los archivos JSON a Parquet.\n",
    "for json_file in json_files:\n",
    "    # Construir la ruta completa del archivo JSON.\n",
    "    json_file_path = os.path.join(json_folder_path, json_file)\n",
    "    \n",
    "    df = pd.read_json(json_file_path, lines=True)\n",
    "    \n",
    "    # Crear la ruta de destino Parquet, usando el nombre del archivo JSON.\n",
    "    parquet_file_path = os.path.join(parquet_folder_path, json_file.replace('.json', '.parquet'))\n",
    "    \n",
    "    df_parquet = df\n",
    "\n",
    "    df_parquet.to_parquet(parquet_file_path, engine='pyarrow', index=False)\n",
    "    \n",
    "    # Eliminamos df en el bucle y liberamos memoria, para ir convirtiendo 1 por iteración.\n",
    "    del df\n",
    "    gc.collect()  \n",
    "\n",
    "    print(f\"Archivo {json_file} procesado y guardado como Parquet en {parquet_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673b5b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_files = [f for f in os.listdir(parquet_folder_path) if f.endswith('.parquet')]\n",
    "\n",
    "df_District_of_Columbia = pd.DataFrame()\n",
    "\n",
    "# Bucle para leer archivos Parquet y concatenar en un sólo DF\n",
    "for file in parquet_files:\n",
    "    file_path = os.path.join(parquet_folder_path, file)\n",
    "    \n",
    "    # Leer el archivo Parquet\n",
    "    df = pd.read_parquet(file_path)\n",
    "    \n",
    "    # Concatenar al DataFrame total\n",
    "    df_District_of_Columbia = pd.concat([df_District_of_Columbia, df], ignore_index=True)\n",
    "    \n",
    "    # Eliminamos df en el bucle y liberamos memoria, para ir procesando y concatenando de 1 por iteración.\n",
    "    del df\n",
    "    gc.collect()  \n",
    "\n",
    "    print(f\"Archivo {file} procesado y agregado\")\n",
    "\n",
    "print(\"Todos los archivos fueron procesados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375445d6",
   "metadata": {},
   "source": [
    "#### Massachusetts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22260f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta de origen\n",
    "json_folder_path = r\"C:/Users/jano_/Documents/Proyecto Final Grupal/Google Maps/reviews-estados/review-Rhode_Island\"\n",
    "\n",
    "# Ruta de destino\n",
    "parquet_folder_path = r\"C:/Users/jano_/Documents/Proyecto Final Grupal/Google Maps/reviews-estados/review-Rhode_Island\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fc0240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de archivos JSON en la carpeta.\n",
    "json_files = [f for f in os.listdir(json_folder_path) if f.endswith('.json')]\n",
    "\n",
    "# Bucle para leer y convertir todos los archivos JSON a Parquet.\n",
    "for json_file in json_files:\n",
    "    # Construir la ruta completa del archivo JSON.\n",
    "    json_file_path = os.path.join(json_folder_path, json_file)\n",
    "    \n",
    "    df = pd.read_json(json_file_path, lines=True)\n",
    "    \n",
    "    # Crear la ruta de destino Parquet, usando el nombre del archivo JSON.\n",
    "    parquet_file_path = os.path.join(parquet_folder_path, json_file.replace('.json', '.parquet'))\n",
    "    \n",
    "    df_parquet = df\n",
    "\n",
    "    df_parquet.to_parquet(parquet_file_path, engine='pyarrow', index=False)\n",
    "    \n",
    "    # Eliminamos df en el bucle y liberamos memoria, para ir convirtiendo 1 por iteración.\n",
    "    del df\n",
    "    gc.collect()  \n",
    "\n",
    "    print(f\"Archivo {json_file} procesado y guardado como Parquet en {parquet_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a3f538",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_files = [f for f in os.listdir(parquet_folder_path) if f.endswith('.parquet')]\n",
    "\n",
    "df_District_of_Columbia = pd.DataFrame()\n",
    "\n",
    "# Bucle para leer archivos Parquet y concatenar en un sólo DF\n",
    "for file in parquet_files:\n",
    "    file_path = os.path.join(parquet_folder_path, file)\n",
    "    \n",
    "    # Leer el archivo Parquet\n",
    "    df = pd.read_parquet(file_path)\n",
    "    \n",
    "    # Concatenar al DataFrame total\n",
    "    df_District_of_Columbia = pd.concat([df_District_of_Columbia, df], ignore_index=True)\n",
    "    \n",
    "    # Eliminamos df en el bucle y liberamos memoria, para ir procesando y concatenando de 1 por iteración.\n",
    "    del df\n",
    "    gc.collect()  \n",
    "\n",
    "    print(f\"Archivo {file} procesado y agregado\")\n",
    "\n",
    "print(\"Todos los archivos fueron procesados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9159ac69",
   "metadata": {},
   "source": [
    "#### Connecticut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12fd4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta de origen\n",
    "json_folder_path = r\"C:/Users/jano_/Documents/Proyecto Final Grupal/Google Maps/reviews-estados/review-Connecticut\"\n",
    "\n",
    "# Ruta de destino\n",
    "parquet_folder_path = r\"C:/Users/jano_/Documents/Proyecto Final Grupal/Google Maps/reviews-estados/review-Connecticut\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584de3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de archivos JSON en la carpeta.\n",
    "json_files = [f for f in os.listdir(json_folder_path) if f.endswith('.json')]\n",
    "\n",
    "# Bucle para leer y convertir todos los archivos JSON a Parquet.\n",
    "for json_file in json_files:\n",
    "    # Construir la ruta completa del archivo JSON.\n",
    "    json_file_path = os.path.join(json_folder_path, json_file)\n",
    "    \n",
    "    df = pd.read_json(json_file_path, lines=True)\n",
    "    \n",
    "    # Crear la ruta de destino Parquet, usando el nombre del archivo JSON.\n",
    "    parquet_file_path = os.path.join(parquet_folder_path, json_file.replace('.json', '.parquet'))\n",
    "    \n",
    "    df_parquet = df\n",
    "\n",
    "    df_parquet.to_parquet(parquet_file_path, engine='pyarrow', index=False)\n",
    "    \n",
    "    # Eliminamos df en el bucle y liberamos memoria, para ir convirtiendo 1 por iteración.\n",
    "    del df\n",
    "    gc.collect()  \n",
    "\n",
    "    print(f\"Archivo {json_file} procesado y guardado como Parquet en {parquet_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3c96bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_files = [f for f in os.listdir(parquet_folder_path) if f.endswith('.parquet')]\n",
    "\n",
    "df_connecticut= pd.DataFrame()\n",
    "\n",
    "# Bucle para leer archivos Parquet y concatenar en un sólo DF\n",
    "for file in parquet_files:\n",
    "    file_path = os.path.join(parquet_folder_path, file)\n",
    "    \n",
    "    # Leer el archivo Parquet\n",
    "    df = pd.read_parquet(file_path)\n",
    "    \n",
    "    # Concatenar al DataFrame total\n",
    "    df_connecticut = pd.concat([df_connecticut, df], ignore_index=True)\n",
    "    \n",
    "    # Eliminamos df en el bucle y liberamos memoria, para ir procesando y concatenando de 1 por iteración.\n",
    "    del df\n",
    "    gc.collect()  \n",
    "\n",
    "    print(f\"Archivo {file} procesado y agregado\")\n",
    "\n",
    "print(\"Todos los archivos fueron procesados\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proyecto_final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
